# VPC3: Vision Transformer Classification Pipeline

Un proyecto integral para entrenar y evaluar modelos Vision Transformer (ViT) y otros modelos de clasificaciÃ³n de imÃ¡genes en el dataset Galaxy10.

## ğŸ¯ DescripciÃ³n General

VPC3 proporciona un pipeline completo para:
- **Entrenar** modelos de visiÃ³n desde Hugging Face (DeiT, ViT, ConvNeXt, MobileViT, Swin)
- **Evaluar** con mÃ©tricas detalladas (precisiÃ³n, recall, F1, matriz de confusiÃ³n)
- **Monitorear** experimentos con MLflow
- **Generar visualizaciones** de mapas de atenciÃ³n (Attention maps)
- **Exportar y servir** modelos con Streamlit

## ğŸ“Š CaracterÃ­sticas

- âœ… Soporte para mÃºltiples arquitecturas de Hugging Face
- âœ… Transformaciones de datos avanzadas (rotaciÃ³n, contraste, morfologÃ­a)
- âœ… Seguimiento de experimentos con MLflow
- âœ… Early stopping y validaciÃ³n cruzada
- âœ… MÃ©tricas completas de evaluaciÃ³n
- âœ… Notebooks interactivos para exploraciÃ³n
- âœ… Interfaz Streamlit para inferencia

## ğŸš€ Inicio RÃ¡pido

### Requisitos Previos

- Python 3.8+
- pip o conda

### InstalaciÃ³n

1. Clona el repositorio:
```bash
git clone <repository-url>
cd vpc3
```

2. Crea un entorno virtual (recomendado):
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. Instala las dependencias:
```bash
pip install -r requirements.txt
```

### Uso BÃ¡sico

Entrena un modelo con una configuraciÃ³n predefinida:

```bash
python app/main.py --config configs/deit-small/config.json
```

O crea tu propia configuraciÃ³n personalizada en `configs/tu-modelo/config.json`.

## ğŸ“ Estructura del Proyecto

```
vpc3/
â”œâ”€â”€ app/                          # AplicaciÃ³n principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py                  # Punto de entrada del entrenamiento
â”‚
â”œâ”€â”€ src/vit/                      # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ data/                     # Carga y gestiÃ³n de datos
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_loader.py       # DataLoader para Galaxy10
â”‚   â”œâ”€â”€ models/                   # Modelos
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ models.py            # Carga modelos desde HF
â”‚   â”œâ”€â”€ train/                    # Entrenamiento
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ trainer.py           # Trainer con MLflow
â”‚   â”œâ”€â”€ eval/                     # EvaluaciÃ³n
â”‚   â”œâ”€â”€ inference/                # Inferencia
â”‚   â”œâ”€â”€ metrics/                  # MÃ©tricas
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ metrics.py           # CÃ¡lculo de mÃ©tricas
â”‚   â”œâ”€â”€ transforms/               # Transformaciones de datos
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ transforms.py        # AugmentaciÃ³n de imÃ¡genes
â”‚   â””â”€â”€ utils/                    # Utilidades
â”‚       â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ configs/                      # Configuraciones por modelo
â”‚   â”œâ”€â”€ deit-small/config.json
â”‚   â”œâ”€â”€ swin-tiny/config.json
â”‚   â”œâ”€â”€ convnext-tiny/config.json
â”‚   â”œâ”€â”€ mobilevit-small/config.json
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ notebooks/                    # AnÃ¡lisis interactivos
â”‚   â”œâ”€â”€ 1. Data visualization.ipynb
â”‚   â”œâ”€â”€ 2. Train.ipynb
â”‚   â””â”€â”€ 3. Attention map.ipynb
â”‚
â”œâ”€â”€ data/                         # Datos
â”‚   â”œâ”€â”€ raw/                     # Datos originales
â”‚   â”œâ”€â”€ interim/                 # Datos procesados temporalmente
â”‚   â””â”€â”€ processed/               # Datos finales
â”‚
â”œâ”€â”€ checkpoints/                  # Modelos entrenados
â”œâ”€â”€ logs/                         # Logs de entrenamiento
â”œâ”€â”€ experiments/                  # Resultados de experimentos
â”œâ”€â”€ scripts/                      # Scripts utilitarios
â”œâ”€â”€ tests/                        # Tests unitarios e integraciÃ³n
â”œâ”€â”€ examples/                     # Ejemplos y plantillas
â”œâ”€â”€ docs/                         # DocumentaciÃ³n
â”œâ”€â”€ requirements.txt              # Dependencias
â””â”€â”€ README.md
```

## ğŸ“‹ Modelos Soportados

El proyecto soporta cualquier modelo de clasificaciÃ³n de imÃ¡genes de Hugging Face. Configuraciones predefinidas incluyen:

| Modelo | Checkpoint | ConfiguraciÃ³n |
|--------|-----------|---------------|
| DeiT Small | `facebook/deit-small-patch16-224` | âœ… |
| Swin Tiny | `microsoft/swin-tiny-patch4-window7-224` | âœ… |
| ConvNeXt Tiny | `facebook/convnext-tiny-224` | âœ… |
| MobileViT Small | `apple/mobilevit-small` | âœ… |

## âš™ï¸ ConfiguraciÃ³n

Cada modelo tiene su propia configuraciÃ³n JSON. Ejemplo (`configs/deit-small/config.json`):

```json
{
  "checkpoint": "facebook/deit-small-patch16-224",
  "batch_size": 16,
  "epochs": 20,
  "learning_rate": 5e-5,
  "early_stopping_patience": 3,
  "img_height": 224,
  "img_width": 224,
  "morph_kernel_size": [7, 7],
  "rotation_degrees": 180,
  "contrast": 0.2,
  "translate": [0.1, 0.1]
}
```

### ParÃ¡metros Configurables

- **checkpoint**: Identificador del modelo en Hugging Face
- **batch_size**: TamaÃ±o del lote para entrenamiento
- **epochs**: NÃºmero de Ã©pocas
- **learning_rate**: Tasa de aprendizaje
- **early_stopping_patience**: Paciencia para early stopping
- **img_height/img_width**: Dimensiones de entrada de imagen
- **morph_kernel_size**: TamaÃ±o del kernel para operaciones morfolÃ³gicas
- **rotation_degrees**: Ãngulos de rotaciÃ³n en augmentaciÃ³n
- **contrast**: Factor de contraste en augmentaciÃ³n
- **translate**: Rango de traslaciÃ³n en pixeles

## ğŸ“š Dataset

El proyecto utiliza el dataset **Galaxy10**, que contiene 17,736 imÃ¡genes de galaxias clasificadas en 10 categorÃ­as:

0. Disturbed
1. Merging
2. Round Smooth
3. Smooth, Cigar shaped
4. Cigar Shaped Smooth
5. Barred Spiral
6. Unbarred Tight Spiral
7. Unbarred Loose Spiral
8. Edge-on without Bulge
9. Edge-on with Bulge

Se descarga automÃ¡ticamente usando el dataset de Hugging Face.

## ğŸ”§ Dependencias Principales

- **torch==2.8.0**: Framework de aprendizaje profundo
- **torchvision==0.23.0**: Modelos y utilidades de visiÃ³n por computadora
- **transformers==4.37.2**: Modelos preentrenados de Hugging Face
- **datasets==4.0.0**: Carga de datasets
- **scikit-learn==1.6.1**: MÃ©tricas y utilidades ML
- **matplotlib==3.10.0**: VisualizaciÃ³n
- **pandas==2.2.2**: Manejo de datos tabulares
- **opencv-python==4.12.0.88**: Procesamiento de imÃ¡genes
- **accelerate==0.28.0**: AceleraciÃ³n distribuida

Ver `requirements.txt` para la lista completa.

## ğŸ“ Notebooks

El proyecto incluye notebooks interactivos para exploraciÃ³n:

1. **Data visualization.ipynb**: AnÃ¡lisis exploratorio del dataset
2. **Train.ipynb**: Proceso de entrenamiento paso a paso
3. **Attention map.ipynb**: VisualizaciÃ³n de mapas de atenciÃ³n

Ejecuta con Jupyter:
```bash
jupyter notebook
```

## ğŸ“Š Monitoreo con MLflow

Los experimentos se registran automÃ¡ticamente en MLflow. Para ver el dashboard:

```bash
mlflow ui
```

Luego abre `http://localhost:5000` en tu navegador.

## ğŸ“ˆ EvaluaciÃ³n y MÃ©tricas

El proyecto calcula automÃ¡ticamente:

- **Accuracy**: PrecisiÃ³n global
- **Precision, Recall, F1-Score**: Por clase y global ponderadas
- **Confusion Matrix**: Matriz de confusiÃ³n

## ğŸ“ Flujo de Trabajo TÃ­pico

1. **ConfiguraciÃ³n**: Crea o edita `configs/mi-modelo/config.json`
2. **Entrenamiento**: `python app/main.py --config configs/mi-modelo/config.json`
3. **Monitoreo**: Abre MLflow para ver mÃ©tricas en tiempo real
4. **EvaluaciÃ³n**: Revisa mÃ©tricas finales y matriz de confusiÃ³n
5. **ExportaciÃ³n**: El modelo se guarda en `checkpoints/`
6. **Inferencia**: Usa Streamlit o importa el modelo en cÃ³digo

## ğŸ‘¤ Autor

**Kevin Cajachuan**

- GitHub: [@Kajachuan](https://github.com/Kajachuan)